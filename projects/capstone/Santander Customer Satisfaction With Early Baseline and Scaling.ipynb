{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Santander Customer Satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75818, 370)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers: 76020\n",
      "Number of satisfied customers: 73012\n",
      "Number of unsatisfied customers: 3008\n",
      "Satisfaction rate: 96.04%\n",
      "Number of features: 369\n"
     ]
    }
   ],
   "source": [
    "n_customers = len(train)\n",
    "n_unsatisfied = train.TARGET.sum()\n",
    "n_satisfied = (train.TARGET==0).sum()\n",
    "satisfaction_rate = float(n_satisfied)/n_customers\n",
    "\n",
    "features = test.columns.drop('ID').tolist()\n",
    "n_features = len(features)\n",
    "\n",
    "print(\"Total number of customers: {}\".format(n_customers))\n",
    "print(\"Number of satisfied customers: {}\".format(n_satisfied))\n",
    "print(\"Number of unsatisfied customers: {}\".format(n_unsatisfied))\n",
    "print(\"Satisfaction rate: {:.2f}%\".format(satisfaction_rate*100))\n",
    "print(\"Number of features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ID Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-5da4cf54f6b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No repeated ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vieiraad/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ID'"
     ]
    }
   ],
   "source": [
    "if len(set(train.ID)) == len(train):\n",
    "    print('No repeated ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_id = train.ID\n",
    "test_id = test.ID\n",
    "train.drop('ID', inplace=True, axis=1)\n",
    "test.drop('ID', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGJCAYAAACkUBhuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c48db10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.TARGET);\n",
    "plt.title('Unbalanced dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exploring Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAF0CAYAAABlr5CRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c434950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.dtypes);\n",
    "plt.title('Lots of features. Most integers.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for c in train.select_dtypes('float'):\n",
    "#     sns.distplot(train[c]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replace_weird(dfs, weird = [-999999, 9999999999.00]):\n",
    "    for df in dfs:\n",
    "        modes = df.mode()\n",
    "        for col in df.columns:\n",
    "            if any([i in df[col].values for i in weird]):\n",
    "#                 df['weird_'+col] = df[col].isin(weird)\n",
    "                df[col].mask(df[col].isin(weird), modes[col][0], inplace=True)\n",
    "\n",
    "replace_weird([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_useless(dfs):\n",
    "    remove = []\n",
    "    for df in dfs:\n",
    "        for col in df.columns:\n",
    "            if df[col].std() == 0:\n",
    "                remove.append(col)\n",
    "    for df in dfs:\n",
    "        df.drop(set(remove), axis=1, inplace=True)\n",
    "\n",
    "remove_useless([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated columns on test set are also duplicated on training set.          \n",
      "All duplicated being removed from both sets\n"
     ]
    }
   ],
   "source": [
    "def duplicated(df):\n",
    "    duplicated = []\n",
    "    c = df.columns\n",
    "    for i in range(len(c)-1):\n",
    "        v = df[c[i]].values\n",
    "        for j in range(i+1,len(c)):\n",
    "            if np.array_equal(v,df[c[j]].values):\n",
    "                duplicated.append(c[j])\n",
    "    return set(duplicated)\n",
    "\n",
    "\n",
    "duplicated_train = duplicated(train)\n",
    "duplicated_test = duplicated(test)\n",
    "\n",
    "if duplicated_test.issubset(duplicated_train):\n",
    "    print('Duplicated columns on test set are also duplicated on training set.\\\n",
    "          \\nAll duplicated being removed from both sets')\n",
    "    train.drop(duplicated_train, axis=1, inplace=True)\n",
    "    test.drop(duplicated_train, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = test.columns.tolist()\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for c in train.select_dtypes('float'):\n",
    "#     sns.distplot(train[c]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Scaling\n",
    "- https://discuss.analyticsvidhya.com/t/methods-to-deal-with-zero-values-while-performing-log-transformation-of-variable/2431/3\n",
    "- Robust Scaler\n",
    "- Log Scaler\n",
    "- Scale Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "floats = train.select_dtypes('float').columns\n",
    "\n",
    "min_max_scaler.fit(pd.concat([train,test])[floats])\n",
    "\n",
    "train[floats] = pd.DataFrame(min_max_scaler.transform(train[floats]), columns=floats)\n",
    "test[floats] = pd.DataFrame(min_max_scaler.transform(test[floats]), columns=floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for c in train.select_dtypes('float'):\n",
    "#     sns.distplot(train[c]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "roc_auc_scorer = make_scorer(roc_auc_score, needs_proba=True) # Convert a metric to a scorer.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array(train.drop('TARGET', axis=1))\n",
    "y = np.array(train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All zeros benchmark has ROC_AUC score of 0.5'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'All zeros benchmark has ROC_AUC score of {}'.format(roc_auc_score(train.TARGET, np.zeros_like(train.TARGET)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Baseline\n",
    "- Base Models\n",
    "- Grid Search\n",
    "- Model descriptions, strengths and weakness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6040146013481933"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "cross_val_score(nb_classifier, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression(class_weight={0:0.2, 1:0.8}, random_state=3)\n",
    "cross_val_score(lr_classifier, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5700999301308526"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=3)\n",
    "cross_val_score(dt_classifier, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too slow\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# sv_classifier = SVC()\n",
    "# # cross_val_score(sv_classifier, X, y, cv=3, scoring='roc_auc').mean()\n",
    "\n",
    "print('Too slow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730016643562493"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=3)\n",
    "cross_val_score(mlp_classifier, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621994032545302"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=3)\n",
    "cross_val_score(rf_classifier, X, y, cv=5, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365905994444206"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_classifier = XGBClassifier(random_state=3)\n",
    "cross_val_score(xgb_classifier, X, y, cv=3, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAFoCAYAAADpW6mGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBMSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b747ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train.select_dtypes('int').nunique(), kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def OHE(train = train, test = test, limit=10):\n",
    "    oh_df = pd.concat([train, test])\n",
    "    for c in oh_df.select_dtypes(int):\n",
    "        if oh_df[c].nunique()>2 and oh_df[c].nunique()<limit:\n",
    "            for val in set(oh_df[c]):\n",
    "                train[c+'_oh_' + str(val)] = (train[c].values == val).astype(np.int)\n",
    "                test[c+'_oh_' + str(val)] = (test[c].values == val).astype(np.int)            \n",
    "#             train.drop(c, axis=1)\n",
    "#             test.drop(c, axis=1)\n",
    "\n",
    "OHE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Values sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def values_sum(df):\n",
    "    df['values_sum'] = df[features].sum(axis=1).astype(float)\n",
    "\n",
    "values_sum(train)\n",
    "values_sum(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Count zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_zeros(df):\n",
    "    df['zeros'] = (df[features]==0).sum(axis=1).astype(float)\n",
    "    \n",
    "count_zeros(train)\n",
    "count_zeros(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Value == Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_if_is_mode(df):\n",
    "    modes = df.mode()\n",
    "    for c in features:\n",
    "        df['is_mode_of_'+c] = (df[c]==modes[c][0]).astype(int)\n",
    "\n",
    "check_if_is_mode(train)\n",
    "check_if_is_mode(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.countplot(train.dtypes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for f in train.select_dtypes('float').columns:\n",
    "#     sns.distplot(train[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "floats = train.select_dtypes('float').columns\n",
    "min_max_scaler.fit(pd.concat([train,test])[floats])\n",
    "\n",
    "train[floats] = pd.DataFrame(min_max_scaler.transform(train[floats]), columns=floats)\n",
    "test[floats] = pd.DataFrame(min_max_scaler.transform(test[floats]), columns=floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum non-zero value in data is 0.0000000069\n"
     ]
    }
   ],
   "source": [
    "minimum_float = pd.concat([train.select_dtypes(float), test.select_dtypes(float)]).replace(0,10).min().min()\n",
    "print('Minimum non-zero value in data is {:.10f}'.format(float(minimum_float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for f in train.select_dtypes('float').columns:\n",
    "#     sns.distplot(train[f].apply(lambda x: minimum_float/2 if x==0 else x).apply(np.log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for f in train.select_dtypes('float').columns:\n",
    "#     m = train[f].mode()[0]\n",
    "#     sns.distplot(train[train[f]!=m][f].apply(lambda x: minimum_float/2 if x==0 else x).apply(np.log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "floats = train.select_dtypes('float').columns\n",
    "\n",
    "train[floats] = train[floats].applymap(lambda x: minimum_float/2 if x==0 else x).apply(np.log)\n",
    "test[floats] = test[floats].applymap(lambda x: minimum_float/2 if x==0 else x).apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(data):\n",
    "    n = len(data.drop('TARGET', axis=1).columns)\n",
    "    \n",
    "    X = np.array(data.drop('TARGET', axis=1))\n",
    "    y = np.array(data['TARGET'])\n",
    "    \n",
    "    lr_classifier.fit(X, y)\n",
    "    mlp_classifier.fit(X, y)\n",
    "    xgb_classifier.fit(X, y)\n",
    "\n",
    "    i_mlp = np.absolute(np.dot(mlp_classifier.coefs_[0],mlp_classifier.coefs_[1]).reshape(n))\n",
    "    i_lr = np.absolute(lr_classifier.coef_.reshape(n))\n",
    "    i_xgb = xgb_classifier.feature_importances_\n",
    "    \n",
    "    importances = pd.DataFrame({'mlp': i_mlp, 'lr': i_lr, 'xgb': i_xgb}, index=data.drop('TARGET', axis=1).columns)\n",
    "    importances = importances / importances.max()\n",
    "    importances['i'] = importances.sum(axis=1)\n",
    "    importances.sort_values('i', ascending=False, inplace=True)\n",
    "    \n",
    "    return importances\n",
    "\n",
    "importances = get_feature_importances(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.distplot(importances.i, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_important = len(importances.loc[importances.i>importances.i.mean()])\n",
    "n_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAF9CAYAAACDJ4v1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAGylJREFUeJzt3X+sV3X9wPEX19vnXoJr3q73AiMotSWIyaUrNjKkqbPZ\nRFZX3aqZ2Y9byc1mWwvsh6WVKKU1+TExM8O5EDA3+rEa1beSKARCCGTtQpbXyeVzBQzhej/C/Xz/\naN66XeHet5z7uffq47Exd8953/N+cz47+vTz64woFovFAADop7LBXgAAMLyIBwAgiXgAAJKIBwAg\niXgAAJKIBwAgiXgAAJKIBwAgiXgAAJK84ngoFAoxe/bseOyxx7q3tba2xrXXXhvTpk2Lyy67LNat\nW9fjd/74xz/G7Nmzo76+Pj760Y/GU0899cpXDgAMilcUD4VCIT7/+c9HS0tLj+1z586Nurq6WL16\ndVx++eXR3Nwce/bsiYiIZ555JubOnRuNjY2xevXqqK6ujrlz55743wAAKKnkeNi1a1dcddVV0dra\n2mP7+vXr46mnnoqbb745Tj/99Ghqaor6+vpYtWpVREQ89NBD8fa3vz0++tGPxhlnnBG33nprPP30\n0z2euQAAhr7keNiwYUPMmDEjVqxYEf99T62tW7fGlClToqKiontbQ0NDbNmypXv/9OnTu/dVVlbG\nWWedFX/5y19OZP0AQImVp/7CBz/4wZfdns/no66urse2mpqaaGtri4iIvXv39tp/6qmndu8HAIaH\n5Hg4lo6Ojsjlcj225XK5KBQKERHxwgsvHHd/X84999zo7OzsFSAAwPHt3bs3KioqYuPGjZkcL7OP\nalZUVPQKgUKhEJWVlf3a35dCoRBHjx7NZrEA8Bpy9OjRfv/Pen9k9szDmDFjen36or29PWpra7v3\n5/P5XvsnT57cr+O/dJxf//rXGawWAF47LrrookyPl9kzD1OnTo0dO3b0KJtNmzZFfX199/7Nmzd3\n7+vo6IgdO3Z07wcAhofM4uG8886LcePGxbx586KlpSWWLVsW27ZtiyuuuCIiIhobG2Pz5s1xzz33\nREtLS8yfPz8mTpwY5513XlZLAABK4ITiYcSIEf85UFlZLFmyJPL5fDQ2NsaaNWti8eLFMXbs2IiI\nGD9+fNx1112xevXquPLKK+PgwYOxaNGiE1s9AFByI4r//WUNQ9hLr9d4zwMApMn6v6FujAUAJBEP\nAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS\n8QAAJBEPAEAS8QAAJBEPAECS8sFewFD04osvxtGjR487prKyskSrAYChRTy8jJ/+6tF4MUYec39H\nx+F436y3R21tbQlXBQBDg3h4GeW5kTFy9Nhj7h/xrwMlXA0ADC3e8wAAJBEPAEAS8QAAJBEPAEAS\n8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAA\nJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJMk0\nHvbs2ROf/vSno6GhIS666KK4//77u/e1trbGtddeG9OmTYvLLrss1q1bl+XUAECJZBoPn/vc52LU\nqFHxk5/8JG688cb47ne/G2vXro2IiOuuuy7q6upi9erVcfnll0dzc3Ps2bMny+kBgBIoz+pA//rX\nv+Lxxx+Pb37zmzFx4sSYOHFizJw5M/70pz/F6NGjo7W1NVauXBkVFRXR1NQU69evj1WrVkVzc3NW\nSwAASiCzZx4qKytj5MiRsXr16jhy5Ejs3r07Nm/eHJMnT47HH388pkyZEhUVFd3jGxoaYsuWLVlN\nDwCUSGbxkMvl4qtf/Wr8+Mc/jqlTp8b73ve+uOCCC6KxsTHy+XzU1dX1GF9TUxNtbW1ZTQ8AlEhm\nL1tEROzatSsuvPDC+PjHPx5/+9vf4pZbbokZM2ZER0dH5HK5HmNzuVwUCoUspwcASiCzeHjpPQy/\n//3vI5fLxVlnnRV79uyJpUuXxowZM+LAgQM9xhcKhaisrMxqegCgRDJ72WL79u3xlre8pcczDJMn\nT45nnnkmxowZE/l8vsf49vb2qK2tzWp6AKBEMouHurq6+Mc//hFHjhzp3rZ79+5405veFFOnTo3t\n27f3eJli06ZNUV9fn9X0AECJZBYPF154YZSXl8eXv/zlePLJJ+M3v/lN3H333fGRj3wkpk+fHuPG\njYt58+ZFS0tLLFu2LLZt2xZXXHFFVtMDACWSWTyMHj06fvjDH0Y+n48rr7wybrvttpg7d25ceeWV\nUVZWFkuXLo18Ph+NjY2xZs2aWLx4cYwdOzar6QGAEsn00xZnnHFG3HvvvS+7b8KECbF8+fIspwMA\nBoEbYwEAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBE\nPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAA\nScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQD\nAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScQDAJBEPAAAScoHewHD\nUVdXV+zbty/Kyo7fXtXV1X2OAYDhJtN4KBQKceutt8bPfvazyOVy0djYGDfccENERLS2tsZXvvKV\n2LJlS4wfPz7mz58f559/fpbTl8zh5w/G2g1tUVd7+JhjDh06GLPfMyVqampKuDIAGHiZxsM3vvGN\n2LBhQ/zgBz+I559/Pm644YYYP358XHXVVXHdddfF5MmTY/Xq1bF27dpobm6OX/ziFzF27Ngsl1Ay\nr3/96Kh6Q/VgLwMASi6zeHjuuefi4Ycfjh/+8Idx9tlnR0TExz72sXj88cdj4sSJ0draGitXroyK\niopoamqK9evXx6pVq6K5uTmrJQAAJZBZPGzatCmqqqri3HPP7d72yU9+MiIi7r777pgyZUpUVFR0\n72toaIgtW7ZkNT0AUCKZvZvvqaeeivHjx8cjjzwSl156aVx88cWxZMmSKBaLkc/no66ursf4mpqa\naGtry2p6AKBEMnvm4fDhw/Hkk0/GQw89FAsWLIh8Ph9f/epXY+TIkdHR0RG5XK7H+FwuF4VCIavp\nAYASySweTjrppDh06FDccccd3W+CfPrpp+PBBx+Md7/73XHgwIEe4wuFQlRWVmY1PQBQIpm9bFFX\nVxcVFRU9Pj1x2mmnRVtbW4wZMyby+XyP8e3t7VFbW5vV9ABAiWQWD1OnTo3Ozs74xz/+0b1t165d\nMX78+Jg6dWps3769x8sUmzZtivr6+qymBwBKJLN4OO2002LWrFkxb9682LlzZ/zhD3+Ie+65Jz70\noQ/F9OnTY9y4cTFv3rxoaWmJZcuWxbZt2+KKK67IanoAoEQy/e7kb3/72/HmN785PvzhD8f8+fPj\n6quvjg9/+MNRVlYWS5cujXw+H42NjbFmzZpYvHjxsP2CKAB4Lcv0GyZHjx4dCxYsiAULFvTaN2HC\nhFi+fHmW0wEAg8BdmwCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgi\nHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCAJOIBAEgiHgCA\nJOIBAEhSPtgLeLXq6uqKffv2HXdMdXV1lJXpNwCGF/EwQA4fOhhr/9wep576/MvuP3ToYMx+z5So\nqakp8coA4MSIhwE08vWjo+oN1YO9DADIlOfMAYAk4gEASCIeAIAk4gEASCIeAIAk4gEASCIeAIAk\n4gEASCIeAIAk4gEASCIeAIAk4gEASCIeAIAk4gEASCIeAIAk4gEASCIeAIAk4gEASCIeAIAk4gEA\nSCIeAIAk4gEASCIeAIAkAxYPTU1NMX/+/O6fW1tb49prr41p06bFZZddFuvWrRuoqQGAATQg8fCz\nn/0sfv/73/fYNnfu3Kirq4vVq1fH5ZdfHs3NzbFnz56BmB4AGECZx8Nzzz0XCxcujHPOOad72/r1\n6+Opp56Km2++OU4//fRoamqK+vr6WLVqVdbTAwADrDzrA952220xZ86c2Lt3b/e2rVu3xpQpU6Ki\noqJ7W0NDQ2zZsiXr6QGAAZbpMw/r16+PTZs2xdy5c3tsz+fzUVdX12NbTU1NtLW1ZTk9AFACmcVD\noVCIr33ta3HTTTdFLpfrsa+jo6PXtlwuF4VCIavpAYASySwe7rrrrjj77LPjXe96V699FRUVvUKh\nUChEZWVlVtMDACWS2Xsefv7zn8ezzz4b06ZNi4iIF198MSIifvnLX8anP/3paGlp6TG+vb09amtr\ns5oeACiRzOLhgQceiCNHjnT/vHDhwoiI+MIXvhBPP/10LFu2LAqFQvfLF5s2bYpzzz03q+kBgBLJ\nLB7GjRvX4+dRo0ZFRMSECRNi/PjxMW7cuJg3b15cd9118Zvf/Ca2bdsWCxYsyGp6AKBESvL11GVl\nZbFkyZLI5/PR2NgYa9asicWLF8fYsWNLMT0AkKHMv+fhJbfeemuPnydMmBDLly8fqOkAgBJxYywA\nIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4\nAACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACS\niAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcA\nIIl4AACSlA/2Al6rurq6Yt++fX2Oq66ujrIyjQfA0CEeBsnhQwdj7Z/b49RTnz/mmEOHDsbs90yJ\nmpqaEq4MAI5PPAyika8fHVVvqB7sZQBAEvEwhHlpA4ChSDwMYV7aAGAoEg9DnJc2ABhqPNcNACQR\nDwBAEvEAACQRDwBAkkzjoa2tLa6//vp45zvfGbNmzYoFCxZEoVCIiIjW1ta49tprY9q0aXHZZZfF\nunXrspwaACiRTOPh+uuvj87OznjwwQfjjjvuiN/+9rfxve99LyIirrvuuqirq4vVq1fH5ZdfHs3N\nzbFnz54spwcASiCzj2ru3r07tm7dGuvWrYs3vvGNEfHvmLj99ttj5syZ0draGitXroyKiopoamqK\n9evXx6pVq6K5uTmrJbwm9eeLpHyJFABZyiweamtr4/vf/353OLzk4MGD8fjjj8eUKVOioqKie3tD\nQ0Ns2bIlq+lfs/r6IilfIgVA1jKLh6qqqjj//PO7fy4Wi/HAAw/EjBkzIp/PR11dXY/xNTU10dbW\nltX0r2m+SAqAUhqw57Jvv/32eOKJJ+KGG26Ijo6OyOVyPfbncrnuN1MCAMPHgMTDwoULY/ny5fHt\nb3873vrWt0ZFRUWvUCgUClFZWTkQ0wMAAyjzeLjlllvi/vvvj4ULF8bFF18cERFjxoyJfD7fY1x7\ne3vU1tZmPT0AMMAyjYdFixbFihUr4s4774xLL720e/vUqVNjx44dPZ592LRpU9TX12c5PQBQApnF\nw65du2Lp0qXR1NQU06ZNi/b29u4/5513XowbNy7mzZsXLS0tsWzZsti2bVtcccUVWU0PAJRIZp+2\n+PWvfx1dXV2xdOnSWLp0aUT8+xMXI0aMiCeeeCIWL14cX/rSl6KxsTEmTpwYixcvjrFjx2Y1PQBQ\nIpnFQ1NTUzQ1NR1z/8SJE2P58uVZTQcADBJfOwgAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAA\nJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAEAS8QAAJBEPAECS8sFeAIOv\nq6sr9u/ff9wx1dXVUVamNQEQD0TE/v37Y83/bY9Ro6pedv+hQwdj9numRE1NTYlXBsBQJB6IiIhR\no6qi6g3Vg70MAIYBz0MDAEnEAwCQRDwAAEnEAwCQRDwAAEnEAwCQRDwAAEnEAwCQRDwAAEnEAwCQ\nRDwAAEnEAwCQRDwAAEnEAwCQRDwAAEnEAwCQRDwAAEnEAwCQRDwAAEnKB3sBDKyurq7Yt2/fccfs\n27cvisXiCR0jIqK6ujrKyo7do11dXbF///4TOgYAg088vModPnQw1v65PU499fljjtm75+kYdXJ1\nnHzKKz/GoUMHY/Z7pkRNTc0xx+zfvz/W/N/2GDWq6hUfA4DBJx5eA0a+fnRUvaH6mPufP/jcCR+j\nv0aNqsrkOAAMHvFAJrJ4eQSA4UE8kIksXh4BYHgQD2Qmi5dHABj6vK0dAEgiHgCAJOIBAEgiHgCA\nJCWNh0KhEDfeeGNMnz49Zs6cGffdd18ppwcAMlDST1vcdtttsWPHjli+fHm0trbGF7/4xRg/fnxc\ncsklpVwGAHACShYPHR0dsWrVqrj33ntj0qRJMWnSpPjEJz4RDzzwgHig3/pzf4yurq6IiGPeI6Ov\n/S850fts9Getfc2TxTFebbI6J+61Mnic+96G2zkpWTzs3Lkzjh49GvX19d3bGhoa4u677y7VEngV\n6Ov+GBH//jKqsvLXxamn1r2i/RHZ3GejP2vta54sjvFqk9U5ca+VwePc9zbczknJ4iGfz8cpp5wS\n5eX/mbKmpiY6Oztj//79UV3tfgf0T1/3x3j+4HMx4qTXHXNMX/uzlMW9PNwPpLeszolzO3ic+96G\n0zkp6csWuVyux7aXfi4UCn3+fj6fjyNHjsRFF100IOv7b4c7OmNE2UnH3H/kyJEoFotx0knHHnP0\n6JGIGHHMMX3tz2rMUDlGf8YUu7rirtxJfRzjaHQWjsaI4zx1l8Xfpz9r6Ut/1trXPFkc49Umq3PS\n13Fea+e1lJz73vpzTpaMzL3ily2eeeaZTM9nyeKhoqKiVyS89PPIkSP7/P1cLleymyq9fmTF8QdU\n9Oe05U5wf1Zjhsox+jvm+MrKyuJ1r3vdCc5z4uvoj/6tdeCP8WqT1TlxbgePc9/bQJ+T8vLyXv8D\nf0LHy+xIfRgzZkwcOHAgurq6usupvb09Kisr4+STT+7z9zdu3DjQSwQA+qFkb9ucPHlylJeXx5Yt\nW7q3bdy4Mc4+++xSLQEAyEDJ4qGysjLmzJkTN910U2zbti3Wrl0b9913X1xzzTWlWgIAkIERxVK9\nkSAiXnjhhfj6178ev/zlL6Oqqio+8YlPxNVXX12q6QGADJQ0HgCA4W9ofFUVADBsiAcAIIl4AACS\niAcAIIl4AACSDKl4KBQKceONN8b06dNj5syZcd999x1z7I4dO+Kqq66K+vr6uPLKK2P79u0lXCn9\nkfJ4fuYzn4lJkybF5MmTu//5u9/9roSrpb8KhULMnj07HnvssWOOcX0OL/15TF2jQ19bW1tcf/31\n8c53vjNmzZoVCxYsOOa9o070Gh1S8XDbbbfFjh07Yvny5XHTTTfFokWL4le/+lWvcR0dHdHU1BTT\np0+Phx9+OOrr6+NTn/pUvPDCC4Owao6lv49nRMTu3bvjO9/5Tjz66KOxbt26ePTRR+Nd73pXiVdM\nXwqFQnz+85+PlpaWY45xfQ4v/XlMI1yjw8H1118fnZ2d8eCDD8Ydd9wRv/3tb+N73/ter3GZXKPF\nIeLw4cPFc845p/jYY491b1uyZEnx6quv7jV25cqVxYsvvrjHtksuuaT4k5/8ZMDXSf+kPJ6dnZ3F\ns846q/jkk0+WcokkamlpKc6ZM6c4Z86c4qRJk4obNmx42XGuz+Gjv4+pa3To27VrV3HSpEnFZ599\ntnvbT3/60+IFF1zQa2wW1+iQeeZh586dcfTo0aivr+/e1tDQEFu3bu01duvWrdHQ0NBj2zve8Y74\ny1/+MuDrpH9SHs+///3vMWLEiJgwYUIpl0iiDRs2xIwZM2LFihXHvcOt63P46O9j6hod+mpra+P7\n3/9+vPGNb+zeViwW4+DBg73GZnGNluyumn3J5/NxyimnRHn5f5ZUU1MTnZ2dsX///qiuru7evnfv\n3njb297W4/dramr6fNqN0kl5PHft2hWjR4+OL3zhC/HnP/85xo0bF5/97GfjggsuGIylcwwf/OAH\n+zXO9Tl89PcxdY0OfVVVVXH++ed3/1wsFuOBBx542ZeWsrhGh8wzDx0dHb3uNf7Sz//7ho8XXnjh\nZcce640hlF7K47l79+7o7OyMmTNnxr333huzZs2Kz3zmM95kN0y5Pl99XKPDz+233x47d+6MG264\node+LK7RIfPMQ0VFRa+Fv/TzyJEj+zW2srJyYBdJv6U8ns3NzXHNNddEVVVVRESceeaZ8de//jVW\nrFgRN998c2kWTGZcn68+rtHhZeHChbF8+fL47ne/G2eccUav/Vlco0PmmYcxY8bEgQMHoqurq3tb\ne3t7VFZWxsknn9xrbD6f77Gtvb09amtrS7JW+pbyeEZE97+UXnLGGWfE3r17B3ydZM/1+erkGh0e\nbrnllrj//vtj4cKFcfHFF7/smCyu0SETD5MnT47y8vLYsmVL97aNGzfG2Wef3Wvs1KlTe72xY/Pm\nzT3enMfgSnk858+fHzfeeGOPbTt37ozTTjttwNdJ9lyfrz6u0eFh0aJFsWLFirjzzjvj0ksvPea4\nLK7RIRMPlZWVMWfOnLjpppti27ZtsXbt2rjvvvvimmuuiYh/V1FnZ2dERLz3ve+NgwcPxre+9a3Y\ntWtXfOMb34iOjo7jnixKK+XxvPDCC2PNmjXxyCOPxD//+c9YtGhRbN68Oa6++urB/CuQwPX56uMa\nHV527doVS5cujaamppg2bVq0t7d3/4kYgGv0lX2idGB0dHQU582bV5w2bVrxggsuKP7oRz/q3nfm\nmWf2+Azq1q1bi+9///uLU6dOLV511VXFJ554YjCWzHGkPJ4rV64sXnLJJcVzzjmn+IEPfKC4cePG\nwVgy/fS/3wng+hz++npMXaND2913312cNGlSjz9nnnlmcdKkScViMftrdESxeJwP9wIA/I8h87IF\nADA8iAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcAIIl4AACSiAcgE5MmTYpHHnlksJcBlICv\npwYy8eyzz0ZVVVXkcrnBXgowwMQDAJDEyxZAJrxsAa8d4gEASCIeAIAk4gEASCIeAIAk4gEASCIe\nAIAk4gHIxIgRIwZ7CUCJ+JIoACCJZx4AgCTiAQBIIh4AgCTiAQBIIh4AgCTiAQBIIh4AgCTiAQBI\nIh4AgCTiAQBIIh4AgCT/D5GySnrpkcUfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c3cf510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(importances.i.head(n_important), kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373308685490173\n",
      "0.8148828488976902\n",
      "0.8180516809870341\n"
     ]
    }
   ],
   "source": [
    "X_top_features = np.array(train[importances.head(n_important).index])\n",
    "\n",
    "print(cross_val_score(xgb_classifier, X_top_features, y, cv=3, scoring='roc_auc').mean())\n",
    "print(cross_val_score(mlp_classifier, X_top_features, y, cv=3, scoring='roc_auc').mean())\n",
    "print(cross_val_score(lr_classifier, X_top_features, y, cv=3, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = train[list(importances.head(n_important).index)+['TARGET']]\n",
    "test = test[importances.head(n_important).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parameter Optmization\n",
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = np.array(train.drop('TARGET', axis=1))\n",
    "y = np.array(train['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.7660670712, total=   8.0s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.791717709591, total=   8.3s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   16.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.80458973576, total=   6.2s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.795870421442, total=   7.2s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.793305377863, total=   6.7s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.814041637725, total=   5.8s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.775732175648, total=   4.6s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.795980018198, total=   5.7s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.789067589438, total=   5.0s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.781160422095, total=   6.4s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.783012715562, total=   6.7s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.666227761431, total=   4.4s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.792205559343, total=   5.1s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.789236924146, total=   5.6s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.801849561345, total=   5.4s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.79217262339, total=   8.7s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.78874300794, total=   4.9s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.786608317654, total=   4.9s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.780451930428, total=   9.9s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.787795036225, total=   8.9s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.788397154821, total=  10.7s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.805344300732, total=  13.5s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.753299291836, total=   9.4s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.77737759063, total=  11.5s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.768285659907, total=   9.1s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.785367343751, total=   9.1s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.5, total=   9.6s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.749834029836, total=   9.7s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.768482304248, total=   9.3s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.791674037798, total=   9.2s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.785731391576, total=   9.6s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.796543024909, total=   9.5s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.803699725503, total=   9.3s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.773750529167, total=   9.8s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.783625947567, total=  10.2s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.795381973039, total=   9.9s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.742089083231, total=   5.7s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.678288018797, total=   5.5s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.784563325992, total=   7.8s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.789632458529, total=   6.6s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.777970522012, total=   6.0s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.804163358372, total=   6.5s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.783089182612, total=   8.2s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.767941440092, total=   5.6s\n",
      "[CV] activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.797030953502, total=   6.1s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.789163080239, total=   8.3s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.776033550333, total=   8.6s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.765315406086, total=   6.8s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.783701652049, total=   7.2s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.801365636419, total=   6.1s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.795823072186, total=   6.1s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.774083247832, total=   5.8s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.78539288655, total=   6.1s\n",
      "[CV] activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=relu, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.793162780738, total=   6.0s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.758266289143, total=   4.8s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.778864253687, total=   4.6s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.786056477258, total=   5.5s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.777515632902, total=   5.0s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.765564935632, total=   5.1s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.778951424513, total=   5.1s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.324250315862, total=   4.8s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.302473481065, total=   4.7s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.315375945729, total=   5.4s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.756417615426, total=   5.9s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.744994195209, total=   6.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100,), score=0.800437584789, total=   8.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.768386802777, total=   5.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.781366034616, total=   5.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100,), score=0.793237783791, total=   4.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.37125231668, total=   4.7s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.335774776996, total=   4.6s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100,), score=0.292202032226, total=   4.7s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.781187827757, total=  10.4s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.7833303926, total=  11.3s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.695711711721, total=  10.4s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.785618778474, total=   9.8s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.79501654055, total=  11.6s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.778836869549, total=  10.2s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.704920533002, total=   9.8s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.354516452287, total=   9.4s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.344057150112, total=  10.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.779594653463, total=  10.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.762366268495, total=  11.9s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(200, 100, 10), score=0.585672165551, total=  10.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.783031135044, total=  10.4s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.788936637513, total=  13.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(200, 100, 10), score=0.788028680282, total=  10.4s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.712067388925, total=   9.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.626419279369, total=  10.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(200, 100, 10), score=0.300489890089, total=   9.5s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.755341502815, total=   6.2s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.712692530126, total=   7.1s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.676224696516, total=   8.0s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.78167084743, total=   7.0s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.785407552664, total=   6.6s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.786726153232, total=   6.2s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.633267139169, total=   6.5s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.325436190914, total=   6.0s\n",
      "[CV] activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=constant, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.29846050185, total=   6.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.779941464128, total=   7.6s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.771645289304, total=   6.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.0001, hidden_layer_sizes=(100, 50, 10), score=0.733513209436, total=   6.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.779103727522, total=   6.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.77895225037, total=   6.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.001, hidden_layer_sizes=(100, 50, 10), score=0.77474856754, total=   6.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.381557111884, total=   6.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.393928642638, total=   6.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, learning_rate_init=0.01, hidden_layer_sizes=(100, 50, 10), score=0.302284755385, total=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(early_stopping=True)\n",
    "\n",
    "mlp_parameters = {'hidden_layer_sizes': [(100,), (200,100,10), (100,50,10)], \n",
    "                  'learning_rate': ['constant', 'adaptive'],\n",
    "                  'learning_rate_init': [0.0001, 0.001, 0.01],\n",
    "                  'activation': ['relu', 'tanh']}\n",
    "\n",
    "mlp_grid_obj = GridSearchCV(mlp_clf, mlp_parameters, scoring='roc_auc', verbose=1, cv=3)\n",
    "mlp_grid_obj = mlp_grid_obj.fit(X, y)\n",
    "\n",
    "mlp_opt =  mlp_grid_obj.best_estimator_\n",
    "mlp_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.787631988577, total=  21.7s\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.798104597331, total=  13.0s\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   34.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l1, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.808764974058, total=  15.8s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   50.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.805666614259, total=   7.7s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   58.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.809734723184, total=   6.4s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l2, C=0.01, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.821921756192, total=   7.0s\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.787618347194, total=  18.8s\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.798117256072, total=  14.9s\n",
      "[CV] penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l1, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.808771248234, total=  18.7s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.805666737154, total=   7.0s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.809733330313, total=   6.4s\n",
      "[CV] penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.01, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.821914046747, total=   6.3s\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.811797781116, total= 1.1min\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.811976631227, total=  49.4s\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.82198029466, total= 1.2min\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.814992527553, total=  11.9s\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.81478846937, total=  11.0s\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.824956529805, total=   9.9s\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.811787375977, total= 1.1min\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.811980400173, total=  52.2s\n",
      "[CV] penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.821976993541, total= 1.1min\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.814988021391, total=  11.8s\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.814775892563, total=  12.6s\n",
      "[CV] penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.1, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.824976336516, total=  10.8s\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.815386898717, total= 5.0min\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.813560448621, total= 3.9min\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.82415843827, total= 6.3min\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.81624679745, total=  16.5s\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.814077572517, total=  16.9s\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.824458040405, total=  17.3s\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.815398246054, total= 4.9min\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.813573476063, total= 3.7min\n",
      "[CV] penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.824174308243, total= 5.7min\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.816248763775, total=  16.3s\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.814075483211, total=  15.4s\n",
      "[CV] penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=0.5, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.824470014649, total=  17.0s\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.816230001752, total= 6.6min\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.813744676313, total= 5.3min\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.824296593155, total= 8.9min\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.816308982495, total=  19.5s\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.813716040521, total=  19.7s\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=True, class_weight={0: 0.2, 1: 0.8}, score=0.824130019945, total=  21.5s\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.816246182973, total= 6.9min\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.813746274018, total=64.7min\n",
      "[CV] penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l1, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.82429544494, total=13.5min\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.816301526844, total=  24.2s\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.813728576362, total=  23.9s\n",
      "[CV] penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8} \n",
      "[CV]  penalty=l2, C=1.0, fit_intercept=False, class_weight={0: 0.2, 1: 0.8}, score=0.824121654378, total=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 149.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight={0: 0.2, 1: 0.8}, dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_parameters = {'class_weight': [{0:0.2, 1:0.8}],\n",
    "               'penalty': ['l1', 'l2'], \n",
    "               'C': [0.01, 0.1, 0.5, 1.0], \n",
    "               'fit_intercept': [True, False]}\n",
    "\n",
    "    \n",
    "lr_grid_obj = GridSearchCV(lr_clf, lr_parameters, scoring='roc_auc', verbose=1, cv=3)\n",
    "lr_grid_obj = lr_grid_obj.fit(X, y)\n",
    "\n",
    "lr_opt =  lr_grid_obj.best_estimator_\n",
    "lr_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=3 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=3, score=0.811870965295, total= 1.0min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=3 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=3, score=0.80717036547, total= 1.1min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=3 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=3, score=0.824176276612, total= 1.0min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=3 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=3, score=0.820146205315, total= 3.2min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=3 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=3, score=0.821654074634, total= 3.3min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=3 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=3, score=0.836067684658, total= 3.0min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=6, score=0.824010362699, total= 2.0min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=6, score=0.822084266984, total= 2.0min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=6, score=0.836651982635, total= 2.1min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=6, score=0.830362474906, total= 5.8min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=6, score=0.831092906922, total= 5.6min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=6 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=6, score=0.844353963725, total= 5.7min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=9, score=0.822203821603, total= 2.8min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=9, score=0.823663475613, total= 2.7min\n",
      "[CV] n_estimators=100, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=100, learning_rate=0.01, max_depth=9, score=0.836981233326, total= 2.6min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=9, score=0.829410302251, total= 8.3min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=9, score=0.829530289847, total= 8.8min\n",
      "[CV] n_estimators=300, learning_rate=0.01, max_depth=9 ...............\n",
      "[CV]  n_estimators=300, learning_rate=0.01, max_depth=9, score=0.841014708062, total= 8.8min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=3, score=0.831981068054, total= 1.1min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=3, score=0.835757407074, total= 1.0min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=3, score=0.844254130519, total= 1.0min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=3, score=0.830288287082, total= 3.0min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=3, score=0.834177399592, total= 3.0min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=3 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=3, score=0.844327636792, total= 3.0min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=6, score=0.830882445113, total= 2.2min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=6, score=0.836926558534, total= 2.1min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=6, score=0.844463474743, total= 2.2min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=6, score=0.82365759161, total= 5.6min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=6, score=0.827933690812, total= 5.7min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=6 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=6, score=0.836204875863, total= 6.0min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=9, score=0.826390968437, total= 3.0min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=9, score=0.828021912813, total= 2.9min\n",
      "[CV] n_estimators=100, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=100, learning_rate=0.1, max_depth=9, score=0.838087374579, total= 2.9min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=9, score=0.812084987539, total= 8.5min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=9, score=0.816488530054, total= 8.6min\n",
      "[CV] n_estimators=300, learning_rate=0.1, max_depth=9 ................\n",
      "[CV]  n_estimators=300, learning_rate=0.1, max_depth=9, score=0.823511070475, total= 8.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 141.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "xgb_parameters = {'max_depth': [3, 6, 9],\n",
    "                  'learning_rate': [0.01, 0.1],\n",
    "                  'n_estimators': [100, 300]}\n",
    "                \n",
    "xgb_grid_obj = GridSearchCV(xgb_clf, xgb_parameters, scoring='roc_auc', verbose=1, cv=3)\n",
    "xgb_grid_obj = xgb_grid_obj.fit(X, y)\n",
    "\n",
    "xgb_opt =  xgb_grid_obj.best_estimator_\n",
    "xgb_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection & Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902449800215683"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp_opt, X, y, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_opt.fit(X,y)\n",
    "y_pred = mlp_opt.predict_proba(np.array(test))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = y_pred[:,1]\n",
    "sub.to_csv('mlp_opt_0506.csv', index=False)\n",
    "\n",
    "mlp_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148828488976902"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp_classifier, X, y, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_classifier.fit(X,y)\n",
    "y_pred = mlp_classifier.predict_proba(np.array(test))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = y_pred[:,1]\n",
    "sub.to_csv('mlp_classifier_0506.csv', index=False)\n",
    "\n",
    "mlp_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8182647538781861"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_opt, X, y, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight={0: 0.2, 1: 0.8}, dual=False,\n",
       "          fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_opt.fit(X,y)\n",
    "y_pred = lr_opt.predict_proba(np.array(test))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = y_pred[:,1]\n",
    "sub.to_csv('lr_opt_0506.csv', index=False)\n",
    "\n",
    "lr_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837424159463268"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xgb_opt, X, y, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_opt.fit(X,y, eval_metric='auc')\n",
    "y_pred = xgb_opt.predict_proba(np.array(test))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = y_pred[:,1]\n",
    "sub.to_csv('xgb_opt_0506.csv', index=False)\n",
    "\n",
    "xgb_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Undersampling\n",
    "- This dataset is highly unbalanced, so using the new dataset without noise, I made an undersampling as follows: first, I splitted the dataset in the instances which have class label 0 and the instances which have class label 1. Later, I splitted the instances with 0 class into (number_of_class0/number_of_class1) partitions (24 partitions) and I joined each partition with the partition of instances of 1 class label made before. Finally, I ran xgboost on each new balanced partition and I made an average with the predictions of the 24 models.\n",
    "- Add this undersampling method to cross val function, with partameter to toggle on/off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undersample(train, test, model):\n",
    "    zeros = train[train.TARGET==0].sample(frac=1).reset_index(drop=True)\n",
    "    ones = train[train.TARGET==1]\n",
    "\n",
    "    folds = []\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, len(zeros), len(ones)):\n",
    "        zeros_fold = zeros[i:i+len(ones)]\n",
    "        ones_fold = ones.sample(len(zeros_fold))\n",
    "        fold = pd.concat([zeros_fold, ones_fold])\n",
    "        folds.append(fold)\n",
    "\n",
    "    for fold in folds: \n",
    "        X = np.array(fold.drop('TARGET', axis=1))\n",
    "        y = np.array(fold['TARGET'])\n",
    "        model.fit(X, y)\n",
    "        fold_pred = model.predict_proba(np.array(test))[:,1]\n",
    "        predictions.append(fold_pred)\n",
    "    \n",
    "    return pd.DataFrame(predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = undersample(train, test, xgb_opt)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = pred\n",
    "sub.to_csv('undersampling0506.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mlp_opt.fit(X,y)\n",
    "# eval_metric\n",
    "\n",
    "# y_pred = mlp_opt.predict_proba(np.array(test))\n",
    "\n",
    "# sub = pd.DataFrame()\n",
    "# sub['id'] = test_id\n",
    "# sub['target'] = y_pred[:,1]\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ideas\n",
    "- Add noise to target\n",
    "- Add noise to target after folding, and train a regressor.\n",
    "- Replicate datapoints with TARGET=1. \n",
    "- Replicate datapoints with TARGET=1. Add noise.\n",
    "- Unbalanced features: check if they give info about target. Try to combine them. Remove excess.\n",
    "- Remaining features: check if they give info using FacetGrid. Apply transformations and check again. Trying to kernel trick.\n",
    "- Simplyfy cross-validation using only sklearn's cross_val_score.\n",
    "- Remove datapoints that have outliers if target=0\n",
    "- Submit using Kaggle api. import kaggle\n",
    "- plotar distribuicao dos scores finais da competicao\n",
    "- mostrar minha posicao comparada as outras notas sem rankear. estara mto mais proxima do primeiro lugar do que do benchmark\n",
    "- ao terminar o projeto, responder email antigo da cristina junqueira\n",
    "- Review previous projects' and live's notebooks ot see if there's something to be added\n",
    "- Test the baseline with unprocessed data\n",
    "- Test the baseline with unscaled data\n",
    "- GridSearch again at the end, after feature engineering\n",
    "- SVM on low importance features.\n",
    "- drop duplicated columns. `train.T.drop_duplicates().T`\n",
    "- fit scaler to whole data (train + test)\n",
    "- Try more base models with final data\n",
    "- Train models only on misclassified datapoints to serve as features for the final model\n",
    "- Link MLP http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "- log scaler\n",
    "- OneHotEncode'em all\n",
    "- Binary feature for each feature on the dataset. `1 if feature == feature.mode() else 0`\n",
    "- Add column that sum zeros on row. `train['zeros'] = (train==0).sum(axis=1).astype(float)`\n",
    "- Add column that sums values in row. \n",
    "- PCA and other dimensionality reduction on low importance features.\n",
    "- ONE-HOT encode features with more than 2 and less than 'limit' unique values\n",
    "- Test importance of new features\n",
    "- Stacking / Voting\n",
    "- Classifiers as features\n",
    "- Sklearn Pipeline\n",
    "- Sklearn feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Rascunho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stacking Models\n",
    "\n",
    "# def stack(train, test, models):    \n",
    "#     X_train = np.array(train.drop('TARGET', axis=1))\n",
    "#     y_train = np.array(train['TARGET'])\n",
    "#     X_test = np.array(test)\n",
    "    \n",
    "#     train_probas = []\n",
    "#     test_probas = []\n",
    "\n",
    "#     for model in models:\n",
    "#         model.fit(X_train, y_train)\n",
    "#         train_probas.append(model.predict_proba(X_train)[:,1])\n",
    "#         test_probas.append(model.predict_proba(X_test)[:,1])\n",
    "        \n",
    "#     stack_perceptron = MLPClassifier(hidden (3,2), early)\n",
    "    \n",
    "#     stack_perceptron.fit(train_probas, y_train)\n",
    "#     stack_perceptron.predict_proba(test_probas)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "#        beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "#        hidden_layer_sizes=(200, 100, 10), learning_rate='constant',\n",
    "#        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "#        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "#        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "#        verbose=False, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LogisticRegression(C=0.1, class_weight={0: 0.2, 1: 0.8}, dual=False,\n",
    "#           fit_intercept=False, intercept_scaling=1, max_iter=100,\n",
    "#           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "#           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "#        max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "#        n_jobs=-1, nthread=None, objective='binary:logistic',\n",
    "#        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "#        seed=None, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# XGBoost params\n",
    "xgb_params = {}\n",
    "xgb_params['learning_rate'] = 0.2\n",
    "xgb_params['n_estimators'] = 10\n",
    "xgb_params['max_depth'] = 4\n",
    "xgb_params['subsample'] = 0.9\n",
    "xgb_params['colsample_bytree'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(X,y, eval_metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# - Missing values. `train.columns[train.isnull().any()].tolist()`\n",
    "# - Outliers and strange values\n",
    "# - Remove duplicated features\n",
    "# - Remove useless features\n",
    "# - Remove useless and duplicated features checking it not only on training set but also on testing set (but maybe they could be useful on validation set).\n",
    "# - This dataset has some repeated instances but with both class label, so that instances are noise. What I made was extract that noisy instances from the complete dataset. After that, I splitted the resulting complete dataset in 5 partitions and I ran xgboost on each one. Then, I made a majority vote of the five resulting predictions for each noisy instance that I extrated at the begining. Finally, I inserted that instances with the real class label.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from time import time\n",
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import random\n",
    "# from collections import Counter\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import kaggle\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB as NaiveBayes\n",
    "# from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# import itertools\n",
    "# import missingno as msno\n",
    "# import gc\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB as NaiveBayes\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.svm import SVC as SVM\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.mixture import GaussianMixture as GM\n",
    "# from hyperopt.pyll.base import scope\n",
    "# from hyperopt.pyll.stochastic import sample\n",
    "# from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "### Viz\n",
    "\n",
    "# sns.palplot(sns.color_palette())\n",
    "\n",
    "# from IPython.display import display # Allows the use of display() for DataFrames\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "# pd.options.display.float_format = '{:.2f}'.format\n",
    "# # sns.set(color_codes=True, palette=sns.palplot(sns.cubehelix_palette(8)))\n",
    "# # sns.set_palette(\"cubehelix_palette\")\n",
    "# %matplotlib inline\n",
    "# # set_matplotlib_formats('pdf', 'png')\n",
    "# rc={'savefig.dpi': 75,    'figure.autolayout': False,    'figure.figsize': [8, 6],    'axes.labelsize': 18,    'axes.titlesize': 18,    'font.size': 18,    'lines.linewidth': 2.0,    'lines.markersize': 8,    'legend.fontsize': 16,    'xtick.labelsize': 16,    'ytick.labelsize': 16,    }\n",
    "# # sns.set(style='dark')\n",
    "# sns.set(style='dark',rc=rc)\n",
    "# # default_color = '#56B4E9'\n",
    "# colormap = plt.cm.cool\n",
    "# # Import supplementary visualizations code visuals.py\n",
    "# # import visuals as vs\n",
    "# # Setting working directory\n",
    "# # path = '../data/raw/'\n",
    "# sns.set_palette(sns.cubehelix_palette(50))\n",
    "# sns.set_palette('GnBu_d')\n",
    "# sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
